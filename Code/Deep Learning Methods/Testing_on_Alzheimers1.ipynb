{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T16:09:49.528522Z",
     "start_time": "2024-04-23T16:09:49.520199Z"
    }
   },
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from DESSA import DESSA\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "sys.path.append('../Metaheuristic Algorithms/')  # Ensure the DESSA module is accessible\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T16:10:04.852875Z",
     "start_time": "2024-04-23T16:10:04.747741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create an instance of the ImageDataGenerator for data normalization and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,   # Normalize pixel values to be between 0 and 1\n",
    "    validation_split=0.2  # Use 20% of the data for validation\n",
    ")\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "train_directory = '/Users/issackondreddy/Desktop/Education/Projects/Cancer Detection/Data/Dataset'\n",
    "\n",
    "# Setup the training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size=(32, 32),  # Resize images to 32x32 for model compatibility\n",
    "    batch_size=4,  # Smaller batch size for quick testing\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='training',  # Use the training subset of images\n",
    "    shuffle=True  # Shuffle the images to reduce model bias\n",
    ")\n",
    "\n",
    "# Setup the validation data generator\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=4,  # Consistent batch size with training for simplicity\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # Use the validation subset of images\n",
    "    shuffle=True\n",
    ")"
   ],
   "id": "b4ef18f5bd22ab6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 images belonging to 4 classes.\n",
      "Found 1279 images belonging to 4 classes.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T16:10:12.672784Z",
     "start_time": "2024-04-23T16:10:12.667892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_cnn_model(params, input_shape=(224, 224, 3), num_classes=4):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)  # We add a fully-connected layer as before\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Freeze all the layers in the base VGG16 model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ],
   "id": "13e878bbd4ca7d7a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T16:10:33.615308Z",
     "start_time": "2024-04-23T16:10:21.716638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bounds = [(16, 64), (2, 5), (0.1, 0.5)]  # Example bounds, adjust as needed\n",
    "\n",
    "dessa_optimizer = DESSA(lambda params: -create_cnn_model(params).evaluate(validation_generator, steps=1)[1],\n",
    "                        bounds, population_size=5, iterations=1)\n",
    "best_params, best_fitness, fitness_history = dessa_optimizer.optimize()\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Validation Accuracy:\", -best_fitness)"
   ],
   "id": "1c39f931c1b63b67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 1.4150 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.4372 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.3410 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.5214 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x17e72aa20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5650 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x17f9f0cc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0711 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.3587 - accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.4563 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.8170 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.7541 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.7371 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.7127 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.3034 - accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.1633 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.8265 - accuracy: 0.2500\n",
      "Best Parameters: [64.          3.0952419   0.25979188]\n",
      "Best Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T16:52:09.015926Z",
     "start_time": "2024-04-23T16:31:45.712515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_model = create_cnn_model([64, 3.1, 0.26], input_shape=(224, 224, 3), num_classes=4)\n",
    "final_history = final_model.fit(train_generator, epochs=20, validation_data=validation_generator, verbose=1)\n",
    "print(\"Final model accuracy on validation set:\", final_history.history['val_accuracy'][-1])"
   ],
   "id": "a70ff83ca90b0619",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1281/1281 [==============================] - 59s 46ms/step - loss: 0.9496 - accuracy: 0.5368 - val_loss: 1.2699 - val_accuracy: 0.3104\n",
      "Epoch 2/20\n",
      "1281/1281 [==============================] - 68s 53ms/step - loss: 0.8956 - accuracy: 0.5657 - val_loss: 1.1773 - val_accuracy: 0.4034\n",
      "Epoch 3/20\n",
      "1281/1281 [==============================] - 62s 49ms/step - loss: 0.8727 - accuracy: 0.5741 - val_loss: 1.2301 - val_accuracy: 0.4285\n",
      "Epoch 4/20\n",
      "1281/1281 [==============================] - 68s 53ms/step - loss: 0.8547 - accuracy: 0.5899 - val_loss: 1.2796 - val_accuracy: 0.3792\n",
      "Epoch 5/20\n",
      "1281/1281 [==============================] - 76s 60ms/step - loss: 0.8474 - accuracy: 0.5886 - val_loss: 1.2126 - val_accuracy: 0.4058\n",
      "Epoch 6/20\n",
      "1281/1281 [==============================] - 55s 43ms/step - loss: 0.8296 - accuracy: 0.5973 - val_loss: 1.1541 - val_accuracy: 0.4636\n",
      "Epoch 7/20\n",
      "1281/1281 [==============================] - 55s 43ms/step - loss: 0.8196 - accuracy: 0.6028 - val_loss: 1.2513 - val_accuracy: 0.4128\n",
      "Epoch 8/20\n",
      "1281/1281 [==============================] - 82s 64ms/step - loss: 0.8044 - accuracy: 0.6177 - val_loss: 1.2619 - val_accuracy: 0.3948\n",
      "Epoch 9/20\n",
      "1281/1281 [==============================] - 59s 46ms/step - loss: 0.7958 - accuracy: 0.6204 - val_loss: 1.3733 - val_accuracy: 0.3471\n",
      "Epoch 10/20\n",
      "1281/1281 [==============================] - 59s 46ms/step - loss: 0.7813 - accuracy: 0.6282 - val_loss: 1.4128 - val_accuracy: 0.3745\n",
      "Epoch 11/20\n",
      "1281/1281 [==============================] - 59s 46ms/step - loss: 0.7696 - accuracy: 0.6348 - val_loss: 1.3097 - val_accuracy: 0.4206\n",
      "Epoch 12/20\n",
      "1281/1281 [==============================] - 59s 46ms/step - loss: 0.7563 - accuracy: 0.6454 - val_loss: 1.3347 - val_accuracy: 0.3659\n",
      "Epoch 13/20\n",
      "1281/1281 [==============================] - 59s 46ms/step - loss: 0.7482 - accuracy: 0.6501 - val_loss: 1.3671 - val_accuracy: 0.4300\n",
      "Epoch 14/20\n",
      "1281/1281 [==============================] - 58s 45ms/step - loss: 0.7381 - accuracy: 0.6516 - val_loss: 1.2547 - val_accuracy: 0.4378\n",
      "Epoch 15/20\n",
      "1281/1281 [==============================] - 56s 44ms/step - loss: 0.7257 - accuracy: 0.6575 - val_loss: 1.2704 - val_accuracy: 0.4019\n",
      "Epoch 16/20\n",
      "1281/1281 [==============================] - 55s 43ms/step - loss: 0.7156 - accuracy: 0.6647 - val_loss: 1.5152 - val_accuracy: 0.2924\n",
      "Epoch 17/20\n",
      "1281/1281 [==============================] - 55s 43ms/step - loss: 0.7115 - accuracy: 0.6684 - val_loss: 1.6921 - val_accuracy: 0.4848\n",
      "Epoch 18/20\n",
      "1281/1281 [==============================] - 55s 43ms/step - loss: 0.7039 - accuracy: 0.6721 - val_loss: 1.4018 - val_accuracy: 0.4034\n",
      "Epoch 19/20\n",
      "1281/1281 [==============================] - 63s 49ms/step - loss: 0.6914 - accuracy: 0.6766 - val_loss: 1.4868 - val_accuracy: 0.3769\n",
      "Epoch 20/20\n",
      "1281/1281 [==============================] - 60s 47ms/step - loss: 0.6807 - accuracy: 0.6858 - val_loss: 1.4427 - val_accuracy: 0.3753\n",
      "Final model accuracy on validation set: 0.37529319524765015\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "65a79b3b64f37d52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
